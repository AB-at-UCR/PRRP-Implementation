"""
spatial_prrp.py

This module implements the PRRP (P‑Regionalization through Recursive Partitioning)
algorithm for partitioning a set of spatial areas into contiguous regions that exactly
meet given cardinality constraints. The algorithm proceeds in three phases:
    1. Region Growing: A region is grown from a randomly selected seed using a simple
       random-based frontier update while ensuring that the remaining unassigned areas
       contain a contiguous component large enough for the target region.
    2. Region Merging: Any disconnected components among the unassigned areas are merged
       into the current region.
    3. Region Splitting: If the merged region exceeds the target size, excess areas are
       trimmed (and if necessary, areas are restored) so that the region meets the cardinality.
       
A random reference distribution is generated by running the algorithm (potentially in parallel)
with different random seeds.
"""

import os
import random
import logging
import multiprocessing
from multiprocessing import Pool, cpu_count
from typing import List, Set, Tuple

import geopandas as gpd
import networkx as nx
from shapely.strtree import STRtree

# ------------------------------------------------------------------------------
# Configure logging (only major events are logged)
# ------------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ------------------------------------------------------------------------------
# 1. Build Spatial Graph from Shapefile
# ------------------------------------------------------------------------------
def create_spatial_network(shp_path: str) -> Tuple[nx.Graph, gpd.GeoDataFrame]:
    """
    Reads a shapefile and constructs a spatial network (as a NetworkX graph).
    Each area (polygon) becomes a node; an edge is added between two nodes if
    their geometries intersect (shared boundaries).

    Parameters:
        shp_path: Path to the shapefile.

    Returns:
        A tuple containing the spatial network (graph) and the GeoDataFrame.
    """
    gdf = gpd.read_file(shp_path)
    net = nx.Graph()
    logger.info(f"Loaded {len(gdf)} areas from the shapefile.")

    # Add nodes for each area (using the index as node id)
    for node_id in gdf.index:
        net.add_node(node_id)

    # Build a spatial index using STRtree for efficient neighbor search.
    spatial_index = STRtree(gdf.geometry)
    geometries = list(gdf.geometry)

    # For each area, query the spatial index to add edges to neighbors.
    for idx, geom in enumerate(geometries):
        possible_idxs = spatial_index.query(geom)
        for jdx in possible_idxs:
            if idx != jdx:
                # Check for intersection (using a threshold if needed)
                if geom.intersects(geometries[jdx]):
                    net.add_edge(gdf.index[idx], gdf.index[jdx])
    logger.info(
        f"Constructed spatial network with {net.number_of_nodes()} nodes and {net.number_of_edges()} edges.")
    return net, gdf


# ------------------------------------------------------------------------------
# 2. Region Growing Phase (Random-based Frontier Expansion)
# ------------------------------------------------------------------------------
def expand_region_randomly(
    net: nx.Graph,
    avail: Set[int],
    target_size: int,
    seed_node: int,
    max_attempts: int = 5
) -> Set[int]:
    """
    Grows a contiguous region from a given seed using a random-based frontier update.
    A feasibility check should be performed before calling this function.

    Parameters:
        net: The spatial network (graph) where nodes represent areas.
        avail: Set of currently unassigned node IDs (will be modified locally).
        target_size: The desired number of nodes in the region.
        seed_node: The starting node for the region.
        max_attempts: Maximum attempts (restarts) allowed to reach the target size.

    Returns:
        A set of node IDs that forms a region exactly of size target_size,
        or an empty set if unsuccessful.
    """
    for attempt in range(max_attempts):
        # Work on a temporary copy of available nodes for this attempt.
        temp_avail = avail.copy()
        region_nodes = set()
        if seed_node not in temp_avail:
            # If provided seed is no longer available, pick one randomly.
            seed_node = random.choice(list(temp_avail))
        region_nodes.add(seed_node)
        temp_avail.remove(seed_node)

        # Initialize the frontier as the unassigned neighbors of the seed.
        frontier = set(net.neighbors(seed_node)).intersection(temp_avail)

        # Grow the region until the target size is reached.
        while len(region_nodes) < target_size and frontier:
            candidate = random.choice(list(frontier))
            region_nodes.add(candidate)
            temp_avail.remove(candidate)
            # Update the frontier: remove the candidate and add its unassigned neighbors.
            frontier.discard(candidate)
            frontier.update(set(net.neighbors(candidate)
                                ).intersection(temp_avail))
        if len(region_nodes) == target_size:
            # On success, update the available set.
            avail.intersection_update(temp_avail)
            logger.info(
                f"Region grown to target size {target_size} on attempt {attempt + 1}.")
            return region_nodes
        else:
            logger.info(
                f"Region growth attempt {attempt + 1} failed to reach target size {target_size}. Retrying...")
    return set()


# ------------------------------------------------------------------------------
# 3. Region Merging Phase (Merge Disconnected Unassigned Components)
# ------------------------------------------------------------------------------
def integrate_components(
    net: nx.Graph,
    avail: Set[int],
    region_nodes: Set[int]
) -> Set[int]:
    """
    Merges any disconnected unassigned components (from avail) into the current region.
    Specifically, if the unassigned nodes (avail) break into multiple connected components,
    then all but the largest component are merged into the current region.

    Parameters:
        net: The spatial network.
        avail: Set of unassigned node IDs.
        region_nodes: The current region as a set of node IDs.

    Returns:
        The updated region (with merged nodes).
    """
    subgraph = net.subgraph(avail)
    components = list(nx.connected_components(subgraph))
    if len(components) > 1:
        largest_comp = max(components, key=len)
        # Merge every other (smaller) component into the region.
        for comp in components:
            if comp != largest_comp:
                region_nodes.update(comp)
                avail.difference_update(comp)
        logger.info("Merged disconnected components into the region.")
    return region_nodes


# ------------------------------------------------------------------------------
# 4. Region Splitting Phase (Adjust Region Size)
# ------------------------------------------------------------------------------
def adjust_region_size(
    net: nx.Graph,
    region_nodes: Set[int],
    target_size: int,
    avail: Set[int]
) -> Set[int]:
    """
    Adjusts the region to exactly meet the target size. If the region exceeds the target,
    boundary nodes are removed at random (with connectivity re‐assessment). If the region
    becomes too small, adjacent available nodes are added.

    Parameters:
        net: The spatial network.
        region_nodes: The current region as a set of node IDs.
        target_size: Desired region size.
        avail: Set of unassigned node IDs (will be updated if nodes are added).

    Returns:
        A set of node IDs representing the adjusted region.
    """
    # Function to compute boundary nodes (nodes in region with neighbor outside region)
    def boundary_nodes(region: Set[int]) -> Set[int]:
        return {n for n in region if set(net.neighbors(n)) - region}

    # If the region is larger than target, remove boundary nodes.
    while len(region_nodes) > target_size:
        b_nodes = boundary_nodes(region_nodes)
        if not b_nodes:
            break
        rem_node = random.choice(list(b_nodes))
        region_nodes.remove(rem_node)
        # Optionally, add the removed node back to available.
        avail.add(rem_node)
        # Reassess connectivity – keep only the largest connected part.
        comps = list(nx.connected_components(net.subgraph(region_nodes)))
        if comps:
            region_nodes = max(comps, key=len)
    # If the region falls below target, try to add adjacent nodes from avail.
    while len(region_nodes) < target_size:
        candidates = set()
        for n in region_nodes:
            candidates.update(set(net.neighbors(n)).intersection(avail))
        if not candidates:
            break
        add_node = random.choice(list(candidates))
        region_nodes.add(add_node)
        avail.remove(add_node)
    logger.info(
        f"Region size adjusted to {len(region_nodes)} (target was {target_size}).")
    return region_nodes


# ------------------------------------------------------------------------------
# 5. Overall PRRP Execution
# ------------------------------------------------------------------------------
def run_prrp(
    net: nx.Graph,
    cardinality_list: List[int],
    max_region_attempts: int = 5
) -> List[Set[int]]:
    """
    Executes the full PRRP algorithm to partition the spatial network into regions
    with the specified cardinalities. The cardinality_list must sum to the total number
    of nodes in the graph.

    Parameters:
        net: The spatial network.
        cardinality_list: A list of integers specifying the target size for each region.
                          It is assumed that the list is sorted in descending order.
        max_region_attempts: Maximum attempts for growing a region.

    Returns:
        A list of regions, where each region is a set of node IDs.
    """
    all_nodes = set(net.nodes())
    available_nodes = all_nodes.copy()
    regions = []
    seed_pool = set()  # A pool of candidate seeds from adjacent areas

    for idx, target in enumerate(cardinality_list):
        # Feasibility check: the largest connected component among available nodes
        # must have at least 'target' nodes.
        comp_sizes = [len(c) for c in nx.connected_components(
            net.subgraph(available_nodes))]
        if not comp_sizes or max(comp_sizes) < target:
            error_msg = f"Feasibility check failed for target {target}. Largest component has {max(comp_sizes) if comp_sizes else 0} nodes."
            logger.error(error_msg)
            raise RuntimeError(error_msg)

        # Select a seed: if seed_pool is nonempty, choose from it; otherwise, choose randomly.
        if seed_pool:
            candidate_seeds = seed_pool.intersection(available_nodes)
            seed = random.choice(list(candidate_seeds)) if candidate_seeds else random.choice(
                list(available_nodes))
            seed_pool.discard(seed)
        else:
            seed = random.choice(list(available_nodes))
        logger.info(
            f"Growing region {idx + 1} with target size {target} using seed {seed}.")

        # Grow region with random frontier expansion.
        region = expand_region_randomly(
            net, available_nodes, target, seed, max_attempts=max_region_attempts)
        if not region or len(region) != target:
            error_msg = f"Region growth failed for region {idx + 1} (target {target})."
            logger.error(error_msg)
            raise RuntimeError(error_msg)

        # Merge any disconnected available components into the region.
        region = integrate_components(net, available_nodes, region)

        # Adjust (split/restore) the region to exactly meet the target.
        region = adjust_region_size(net, region, target, available_nodes)

        # Remove the region’s nodes from the available set.
        available_nodes.difference_update(region)
        regions.append(region)
        logger.info(f"Region {idx + 1} finalized with {len(region)} nodes.")

        # Update seed pool with neighbors of the new region.
        for n in region:
            seed_pool.update(
                set(net.neighbors(n)).intersection(available_nodes))

    # Final verification: all nodes should be assigned.
    if set().union(*regions) != all_nodes:
        error_msg = "Partitioning incomplete: not all nodes were assigned to a region."
        logger.error(error_msg)
        raise RuntimeError(error_msg)
    logger.info("Successfully generated all regions.")
    return regions


# ------------------------------------------------------------------------------
# 6. Parallel Execution of PRRP
# ------------------------------------------------------------------------------
def _prrp_worker(
    seed_val: int,
    net: nx.Graph,
    cardinality_list: List[int],
    max_region_attempts: int
) -> List[Set[int]]:
    """
    Worker function to run PRRP with a specific random seed.
    """
    random.seed(seed_val)
    logger.info(f"Worker started with seed {seed_val}.")
    try:
        sol = run_prrp(net, cardinality_list, max_region_attempts)
        logger.info(
            f"Worker with seed {seed_val} successfully generated a solution.")
        return sol
    except Exception as e:
        logger.error(f"Worker with seed {seed_val} failed: {e}")
        return []


def run_parallel_prrp(
    net: nx.Graph,
    cardinality_list: List[int],
    num_solutions: int,
    num_threads: int = None,
    max_region_attempts: int = 5
) -> List[List[Set[int]]]:
    """
    Generates multiple PRRP solutions in parallel.

    Parameters:
        net: The spatial network.
        cardinality_list: List of target region sizes.
        num_solutions: The number of solutions to generate.
        num_threads: Number of worker threads (defaults to min(num_solutions, CPU cores)).
        max_region_attempts: Maximum attempts for growing each region.

    Returns:
        A list of PRRP solutions (each solution is a list of regions).
    """
    if num_threads is None:
        num_threads = min(num_solutions, cpu_count())
    seeds = [random.randint(0, 2**31 - 1) for _ in range(num_solutions)]
    logger.info(
        f"Generating {num_solutions} solutions using {num_threads} threads.")

    with Pool(processes=num_threads) as pool:
        args = [(s, net, cardinality_list, max_region_attempts) for s in seeds]
        results = pool.starmap(_prrp_worker, args)
    # Filter out any failed solutions.
    solutions = [sol for sol in results if sol]
    logger.info(
        f"Parallel execution completed. {len(solutions)} valid solutions generated.")
    return solutions


# ------------------------------------------------------------------------------
# 7. Main Execution Block (for testing)
# ------------------------------------------------------------------------------
if __name__ == "__main__":
    # Example: Set path to a shapefile (modify the path as needed)
    shapefile_path = os.path.abspath(os.path.join(
        os.getcwd(), 'data', 'your_shapefile.shp'))
    logger.info(f"Shapefile path: {shapefile_path}")

    try:
        spatial_graph, gdf = create_spatial_network(shapefile_path)
    except Exception as e:
        logger.error(f"Failed to load shapefile: {e}")
        exit(1)

    total_nodes = spatial_graph.number_of_nodes()
    num_regions = 5

    # For demonstration, generate target cardinalities that sum to total_nodes.
    # Here we generate (num_regions - 1) random values and assign the remainder to the last region.
    random_targets = [random.randint(5, 15) for _ in range(num_regions - 1)]
    last_target = total_nodes - sum(random_targets)
    cardinality_targets = sorted(random_targets + [last_target], reverse=True)
    logger.info(
        f"Cardinality targets (sorted descending): {cardinality_targets}")

    # Run a single PRRP solution.
    try:
        solution = run_prrp(spatial_graph, cardinality_targets)
        logger.info(
            f"Single PRRP solution generated with {len(solution)} regions.")
    except Exception as e:
        logger.error(f"PRRP execution failed: {e}")
        exit(1)

    # Optionally, run multiple solutions in parallel.
    try:
        parallel_sols = run_parallel_prrp(
            spatial_graph, cardinality_targets, num_solutions=3, num_threads=2)
        logger.info(f"Parallel PRRP generated {len(parallel_sols)} solutions.")
    except Exception as e:
        logger.error(f"Parallel PRRP execution failed: {e}")
