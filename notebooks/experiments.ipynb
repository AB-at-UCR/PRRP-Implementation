{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies from requirements.txt\n",
    "# notebook_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "# os.chdir(notebook_dir)\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Detect if running in an interactive environment (e.g., Jupyter Notebook)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "else:\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "sys.path.insert(0, ROOT_DIR)  # Add root directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from src.spatial_prrp import run_prrp, run_parallel_prrp, grow_region\n",
    "from src.metis_parser import load_graph_from_metis\n",
    "from src.prrp_data_loader import load_shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Success Probablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to shape file : /Volumes/Coding/Projects/PRRP-Implementation/data/cb_2015_42_tract_500k/cb_2015_42_tract_500k.shp\n",
      "Path to graph file : /Volumes/Coding/Projects/PRRP-Implementation/data/PGPgiantcompo.graph\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_algorithm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m         area_data = load_shapefile(dataset_path)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m alg_name, alg_func \u001b[38;5;129;01min\u001b[39;00m algorithms.items():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         success_prob = \u001b[43mevaluate_algorithm\u001b[49m(alg_func, area_data)\n\u001b[32m     47\u001b[39m         success_probabilities[alg_name].append(success_prob)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Calculate average success probabilities\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'evaluate_algorithm' is not defined"
     ]
    }
   ],
   "source": [
    "# Defining the list of following parameters for multiple runs\n",
    "parameters = {\n",
    "    \"num_regions\": [5, 10, 15],\n",
    "    \"cardinalities\": [10, 20, 30],\n",
    "    \"solutions_count\": [10, 20, 30],\n",
    "}\n",
    "\n",
    "success_probabilities = []\n",
    "def evaluate_success_probabilities(algorithm, area_data):\n",
    "    for num_regions in parameters[\"num_regions\"]:\n",
    "        for cardinality in parameters[\"cardinalities\"]:\n",
    "            for solutions_count in parameters[\"solutions_count\"]:\n",
    "                _, valid_solutions = algorithm(area_data, num_regions, cardinality, solutions_count)\n",
    "                success_prob = len(valid_solutions) / solutions_count\n",
    "                print(f\"Success probability for {num_regions} regions, {cardinality} cardinality, {solutions_count} solutions: {success_prob}\")\n",
    "                return success_prob\n",
    "            \n",
    "# Define the algorithms\n",
    "algorithms = {\n",
    "    \"PRRP\": run_parallel_prrp,  # Replace with actual function\n",
    "    \"PRRP-sequential\": run_prrp,  # Replace with actual function\n",
    "    \"PRRP-region-growth-only\": grow_region,  # Replace with actual function\n",
    "}\n",
    "\n",
    "# Path to the data folder\n",
    "data_folder = \"data\"\n",
    "shapefile_path = os.path.join(ROOT_DIR, \"data\", \"cb_2015_42_tract_500k\", \"cb_2015_42_tract_500k.shp\")\n",
    "print(f\"Path to shape file : {shapefile_path}\")\n",
    "\n",
    "graphfile_path = os.path.join(ROOT_DIR, \"data\", \"PGPgiantcompo.graph\")\n",
    "print(f\"Path to graph file : {graphfile_path}\")\n",
    "\n",
    "# List of datasets\n",
    "datasets = [shapefile_path, graphfile_path]\n",
    "\n",
    "# Dictionary to store success probabilities\n",
    "success_probabilities = {alg: [] for alg in algorithms}\n",
    "\n",
    "# Evaluate each algorithm on each dataset\n",
    "for dataset_path in datasets:\n",
    "    if dataset_path.endswith('.graph'):\n",
    "        area_data = load_graph_from_metis(dataset_path)\n",
    "    else:\n",
    "        area_data = load_shapefile(dataset_path)\n",
    "    for alg_name, alg_func in algorithms.items():\n",
    "        success_prob = evaluate_algorithm(alg_func, area_data)\n",
    "        success_probabilities[alg_name].append(success_prob)\n",
    "\n",
    "# Calculate average success probabilities\n",
    "average_success_probabilities = {alg: np.mean(probs) for alg, probs in success_probabilities.items()}\n",
    "\n",
    "print(\"Average Success Probabilities:\")\n",
    "for alg, avg_prob in average_success_probabilities.items():\n",
    "    print(f\"{alg}: {avg_prob:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 08:53:34,161 - INFO - Preparing to generate 10 PRRP solutions using 10 parallel worker(s).\n",
      "2025-03-13 08:53:34,162 - INFO - Generated 10 random seeds for PRRP solutions.\n",
      "2025-03-13 08:53:34,162 - INFO - Starting parallel execution of PRRP solutions using multiprocessing.\n",
      "2025-03-13 08:53:35,055 - INFO - Worker started with seed 927079101.\n",
      "2025-03-13 08:53:35,055 - INFO - Worker started with seed 1139498393.\n",
      "2025-03-13 08:53:35,063 - INFO - Worker started with seed 990236826.\n",
      "2025-03-13 08:53:35,073 - INFO - Worker started with seed 134629034.\n",
      "2025-03-13 08:53:35,076 - INFO - Worker started with seed 596560566.\n",
      "2025-03-13 08:53:35,104 - INFO - Worker started with seed 1697512640.\n",
      "2025-03-13 08:53:35,114 - INFO - Worker started with seed 344184347.\n",
      "2025-03-13 08:53:35,143 - INFO - Worker started with seed 1128911327.\n",
      "2025-03-13 08:53:35,195 - INFO - Worker started with seed 1324919432.\n",
      "2025-03-13 08:53:35,252 - INFO - Worker started with seed 1796225902.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Coding/Projects/PRRP-Implementation/src/spatial_prrp.py\", line 517, in _prrp_worker\n    solution = run_prrp(areas, num_regions, cardinalities, solutions_count)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Coding/Projects/PRRP-Implementation/src/spatial_prrp.py\", line 450, in run_prrp\n    if num_regions != len(cardinalities):\n                      ^^^^^^^^^^^^^^^^^^\nTypeError: object of type 'int' has no len()\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m         area_data = load_shapefile(dataset_path)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m alg_name, alg_func \u001b[38;5;129;01min\u001b[39;00m algorithms.items():\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         effectiveness = \u001b[43mevaluate_effectiveness\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m         effectiveness[alg_name].append(effectiveness)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Calculate average effectiveness\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mevaluate_effectiveness\u001b[39m\u001b[34m(algorithm, area_data, parameters)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cardinality \u001b[38;5;129;01min\u001b[39;00m parameters[\u001b[33m\"\u001b[39m\u001b[33mcardinalities\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m solutions_count \u001b[38;5;129;01min\u001b[39;00m parameters[\u001b[33m\"\u001b[39m\u001b[33msolutions_count\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         no_of_iterations, valid_solutions = \u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43marea_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_regions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcardinality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolutions_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m         effectiveness = \u001b[38;5;28mlen\u001b[39m(valid_solutions) / no_of_iterations \u001b[38;5;28;01mif\u001b[39;00m no_of_iterations > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEffectiveness for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_regions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m regions, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcardinality\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cardinality, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolutions_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m solutions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meffectiveness\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Coding/Projects/PRRP-Implementation/src/spatial_prrp.py:563\u001b[39m, in \u001b[36mrun_parallel_prrp\u001b[39m\u001b[34m(areas, num_regions, cardinalities, solutions_count, num_threads, use_multiprocessing)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=num_threads) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    560\u001b[39m         \u001b[38;5;66;03m# Each worker gets a unique seed, along with the areas, number of regions, and cardinalities.\u001b[39;00m\n\u001b[32m    561\u001b[39m         worker_args = [(seed, areas, num_regions, cardinalities, solutions_count)\n\u001b[32m    562\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds]\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m         solutions = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_prrp_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mParallel execution of PRRP solutions completed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py:375\u001b[39m, in \u001b[36mPool.starmap\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    370\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py:774\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# Calculating Effectiveness metric\n",
    "def evaluate_effectiveness(algorithm, area_data, parameters):\n",
    "    for num_regions in parameters[\"num_regions\"]:\n",
    "        for cardinality in parameters[\"cardinalities\"]:\n",
    "            for solutions_count in parameters[\"solutions_count\"]:\n",
    "                no_of_iterations, valid_solutions = algorithm(area_data, num_regions, cardinality, solutions_count)\n",
    "                effectiveness = len(valid_solutions) / no_of_iterations if no_of_iterations > 0 else 0\n",
    "                print(f\"Effectiveness for {num_regions} regions, {cardinality} cardinality, {solutions_count} solutions: {effectiveness}\")\n",
    "                return effectiveness\n",
    "            \n",
    "effectiveness = {alg: [] for alg in algorithms}\n",
    "\n",
    "# Evaluate each algorithm on each dataset\n",
    "for dataset_path in datasets:\n",
    "    if dataset_path.endswith('.graph'):\n",
    "        area_data = load_graph_from_metis(dataset_path)\n",
    "    else:\n",
    "        area_data = load_shapefile(dataset_path)\n",
    "    for alg_name, alg_func in algorithms.items():\n",
    "        effectiveness = evaluate_effectiveness(alg_func, area_data, parameters)\n",
    "        effectiveness[alg_name].append(effectiveness)\n",
    "\n",
    "# Calculate average effectiveness\n",
    "average_effectiveness = {alg: np.mean(eff) for alg, eff in effectiveness.items()}\n",
    "\n",
    "print(\"Average Effectiveness:\")\n",
    "for alg, avg_eff in average_effectiveness.items():\n",
    "    print(f\"{alg}: {avg_eff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the execution time for the algorithms\n",
    "def evaluate_execution_time(algorithm, area_data, parameters):\n",
    "    for num_regions in parameters[\"num_regions\"]:\n",
    "        for cardinality in parameters[\"cardinalities\"]:\n",
    "            for solutions_count in parameters[\"solutions_count\"]:\n",
    "                # time before the algorithm starts\n",
    "                start_time = time.time()\n",
    "                _ = algorithm(area_data, num_regions, cardinality, solutions_count)\n",
    "                # time after the algorithm ends\n",
    "                end_time = time.time()\n",
    "                print(f\"Execution time for {num_regions} regions, {cardinality} cardinality, {solutions_count} solutions: {time_taken}\")\n",
    "                time_taken = end_time - start_time\n",
    "                return time_taken\n",
    "\n",
    "execution_times = {alg: [] for alg in algorithms}\n",
    "\n",
    "# Evaluate each algorithm on each dataset\n",
    "for dataset_path in datasets:\n",
    "    if dataset_path.endswith('.graph'):\n",
    "        area_data = load_graph_from_metis(dataset_path)\n",
    "    else:\n",
    "        area_data = load_shapefile(dataset_path)\n",
    "    for alg_name, alg_func in algorithms.items():\n",
    "        time_taken = evaluate_execution_time(alg_func, area_data, parameters)\n",
    "        execution_times[alg_name].append(time_taken)\n",
    "\n",
    "# Calculate average execution times\n",
    "average_execution_times = {alg: np.mean(times) for alg, times in execution_times.items()}\n",
    "print(\"Average Execution Times:\")\n",
    "\n",
    "for alg, avg_time in average_execution_times.items():\n",
    "    print(f\"{alg}: {avg_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the completeness metric given by the ratio of the number of regions in the solution to the number of regions in the optimal solution\n",
    "\n",
    "completeness_values = {alg: [] for alg in algorithms}\n",
    "\n",
    "def evaluate_completeness(algorithm, area_data, parameters):\n",
    "    for num_regions in parameters[\"num_regions\"]:\n",
    "        for cardinality in parameters[\"cardinalities\"]:\n",
    "            for solutions_count in parameters[\"solutions_count\"]:\n",
    "                _, valid_solutions = algorithm(area_data, num_regions, cardinality, solutions_count)\n",
    "                # Number of regions in the optimal solution\n",
    "                num_regions = len(area_data)\n",
    "                completeness = 0\n",
    "                for solution in valid_solutions:\n",
    "                    # Number of regions in the solution which is returned by the algorithm\n",
    "                    num_regions_in_solution = len(solution)\n",
    "                    # Completeness metric\n",
    "                    completeness = completeness + num_regions_in_solution / num_regions\n",
    "                print(f\"Completeness for {num_regions} regions, {cardinality} cardinality, {solutions_count} solutions: {completeness}\")\n",
    "                completeness_values.append(completeness)\n",
    "    return completeness_values\n",
    "\n",
    "# Evaluate each algorithm on each dataset\n",
    "for dataset_path in datasets:\n",
    "    if dataset_path.endswith('.graph'):\n",
    "        area_data = load_graph_from_metis(dataset_path)\n",
    "    else:\n",
    "        area_data = load_shapefile(dataset_path)\n",
    "    for alg_name, alg_func in algorithms.items():\n",
    "        completeness = evaluate_completeness(alg_func, area_data, parameters)\n",
    "        completeness_values[alg_name].append(completeness)\n",
    "\n",
    "# Calculate average completeness values\n",
    "average_completeness_values = {alg: np.mean(completeness) for alg, completeness in completeness_values.items()}\n",
    "print(\"Average Completeness Values:\")\n",
    "\n",
    "for alg, avg_completeness in average_completeness_values.items():\n",
    "    print(f\"{alg}: {avg_completeness:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
