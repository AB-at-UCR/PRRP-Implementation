{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRRP Experimental Framework\n",
    "\n",
    "This notebook implements PhaseÂ 1 of the PRRP experimental framework. It supports:\n",
    "\n",
    "1. Loading spatial (shapefile) and graph (METIS) datasets.\n",
    "2. Running experiments on spatial regionalization (using PRRP from `src/spatial_prrp.py`) and graph partitioning (using PRRP from `src/graph_prrp.py` and PyMETIS from `src/pymetis_partition.py`).\n",
    "3. Logging and storing performance metrics (execution time, success probability, effectiveness, and completeness).\n",
    "4. Generating performance visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies from requirements.txt\n",
    "# notebook_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "# os.chdir(notebook_dir)\n",
    "# %pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Detect if running in an interactive environment (e.g., Jupyter Notebook)\n",
    "if \"__file__\" in globals():\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    "else:\n",
    "    ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "sys.path.insert(0, ROOT_DIR)  # Add root directory to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
=======
>>>>>>> 7e74b9833b074fbe7284d13f38ecc6eae56327be
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Add root directory to sys.path so that src modules can be imported\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.insert(0, ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not locate METIS dll. Please set the METIS_DLL environment variable to its full path.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspatial_prrp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_prrp, run_parallel_prrp\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetis_parser\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_graph_from_metis\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpymetis_partition\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_graph_pymetis\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Spatial Computing Projects\\PRRP-Implementation\\src\\pymetis_partition.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmetis\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Set\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\Spatial Computing Projects\\PRRP-Implementation\\prrp\\Lib\\site-packages\\metis.py:438\u001b[39m\n\u001b[32m    436\u001b[39m         _dll = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mCould not locate METIS dll. Please set the METIS_DLL environment variable to its full path.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Wrapping conveniences\u001b[39;00m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapdll\u001b[39m(*argtypes, **kw):\n",
      "\u001b[31mRuntimeError\u001b[39m: Could not locate METIS dll. Please set the METIS_DLL environment variable to its full path."
     ]
    }
   ],
   "source": [
    "# Import PRRP modules\n",
    "from src.prrp_data_loader import load_shapefile, load_metis_graph\n",
    "from src.spatial_prrp import run_prrp, run_parallel_prrp\n",
    "from src.metis_parser import load_graph_from_metis\n",
    "from src.pymetis_partition import partition_graph_pymetis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to shape file : /Volumes/Coding/Projects/PRRP-Implementation/data/cb_2015_42_tract_500k/cb_2015_42_tract_500k.shp\n",
      "Path to graph file : /Volumes/Coding/Projects/PRRP-Implementation/data/PGPgiantcompo.graph\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_algorithm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m         area_data = load_shapefile(dataset_path)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m alg_name, alg_func \u001b[38;5;129;01min\u001b[39;00m algorithms.items():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         success_prob = \u001b[43mevaluate_algorithm\u001b[49m(alg_func, area_data)\n\u001b[32m     47\u001b[39m         success_probabilities[alg_name].append(success_prob)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Calculate average success probabilities\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'evaluate_algorithm' is not defined"
     ]
    }
   ],
   "source": [
    "# Configure logging to display info messages\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration\n",
    "\n",
    "In this section we define:\n",
    "\n",
    "- **Dataset paths:** For the spatial and graph datasets.\n",
    "- **Parameter settings:** Such as the number of regions, sample size (M), maximum retries (MR), and number of cores (Q).\n",
    "- **Output directories:** For saving results and figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths (update these paths as necessary)\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "# Example spatial dataset (census tracts shapefile)\n",
    "spatial_dataset_path = os.path.join(DATA_DIR, \"cb_2015_42_tract_500k\", \"cb_2015_42_tract_500k.shp\")\n",
    "# Example graph dataset in METIS format\n",
    "graph_dataset_path = os.path.join(DATA_DIR, \"PGPgiantcompo.graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters for spatial PRRP\n",
    "spatial_params = {\n",
    "    \"p_percentage\": [0.01, 0.02, 0.03],  # percentage of dataset to use as number of regions\n",
    "    \"sample_sizes\": [10, 50, 100],         # M: sample size (number of solutions)\n",
    "    \"MR_values\": [10, 30, 50],             # MR: max iterations for region formation\n",
    "    \"num_cores\": [1, 2, 4]                 # Q: number of parallel cores\n",
    "}\n",
    "\n",
    "# Experiment parameters for graph partitioning PRRP\n",
    "graph_params = {\n",
    "    \"p_values\": [5, 10, 20],             # number of partitions\n",
    "    \"cardinality_constraints\": [\"Uniform\", \"Skewed\"],  # example constraints\n",
    "    \"MR_values\": [5, 20, 50],\n",
    "    \"MS_values\": [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories for results and figures\n",
    "RESULTS_DIR = os.path.join(ROOT_DIR, \"results/final_results\")\n",
    "FIGURES_DIR = os.path.join(ROOT_DIR, \"results/figures\")\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Experimentation\n",
    "\n",
    "The following helper functions are used to:\n",
    "\n",
    "- Load datasets (spatial or graph).\n",
    "- Compute random target cardinalities for spatial regions.\n",
    "- Run a spatial experiment (using PRRP).\n",
    "- Run a graph partitioning experiment (using both PRRP and PyMETIS for comparison).\n",
    "- Save the results in CSV/JSON format.\n",
    "- Generate visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cardinalities(total_areas, num_regions):\n",
    "    \"\"\"\n",
    "    Generate a list of target cardinalities for regions.\n",
    "    \n",
    "    Parameters:\n",
    "        total_areas (int): Total number of areas in the dataset.\n",
    "        num_regions (int): Number of regions to partition into.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of integers representing the target cardinality for each region.\n",
    "              The sum of cardinalities equals total_areas.\n",
    "    \"\"\"\n",
    "    # Start with a minimum of 2 areas per region (as an example)\n",
    "    cardinalities = [2] * num_regions\n",
    "    remaining = total_areas - 2 * num_regions\n",
    "    # Distribute the remaining areas randomly across regions\n",
    "    for i in range(num_regions):\n",
    "        if remaining <= 0:\n",
    "            break\n",
    "        add = random.randint(0, remaining)\n",
    "        cardinalities[i] += add\n",
    "        remaining -= add\n",
    "    random.shuffle(cardinalities)\n",
    "    return cardinalities\n",
    "\n",
    "def run_spatial_experiment(shapefile_path, p_percentage, M, MR, num_threads):\n",
    "    \"\"\"\n",
    "    Run spatial PRRP experiment on a shapefile dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        shapefile_path (str): Path to the shapefile.\n",
    "        p_percentage (float): Percentage of dataset size used to determine number of regions.\n",
    "        M (int): Sample size (number of PRRP solutions to generate).\n",
    "        MR (int): Maximum iterations to build each region.\n",
    "        num_threads (int): Number of parallel threads/processes.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with experiment metrics and the list of solutions.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading spatial dataset from {shapefile_path} ...\")\n",
    "    areas = load_shapefile(shapefile_path)\n",
    "    if areas is None:\n",
    "        raise FileNotFoundError(f\"Failed to load shapefile from {shapefile_path}\")\n",
    "    \n",
    "    total_areas = len(areas)\n",
    "    num_regions = max(2, int(total_areas * p_percentage))\n",
    "    cardinalities = generate_cardinalities(total_areas, num_regions)\n",
    "    \n",
    "    logger.info(f\"Dataset loaded with {total_areas} areas.\")\n",
    "    logger.info(f\"Parameters: num_regions = {num_regions}, cardinalities = {cardinalities}, M = {M}, MR = {MR}, threads = {num_threads}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Run parallel PRRP (if num_threads > 1) or sequentially\n",
    "    solutions = run_parallel_prrp(areas, num_regions, cardinalities, M, num_threads, use_multiprocessing=(num_threads > 1))\n",
    "    exec_time = time.time() - start_time\n",
    "    \n",
    "    # Dummy metrics â in a real experiment, you would compute success probability, effectiveness, and completeness.\n",
    "    metrics = {\n",
    "        \"execution_time_sec\": exec_time,\n",
    "        \"total_areas\": total_areas,\n",
    "        \"num_regions\": num_regions,\n",
    "        \"cardinalities\": cardinalities,\n",
    "        \"sample_size\": M,\n",
    "        \"MR\": MR,\n",
    "        \"num_threads\": num_threads,\n",
    "        \"num_solutions_generated\": len(solutions)\n",
    "    }\n",
    "    logger.info(f\"Spatial experiment completed in {exec_time:.2f} seconds.\")\n",
    "    \n",
    "    return {\"metrics\": metrics, \"solutions\": solutions}\n",
    "\n",
    "def run_graph_experiment(graph_file_path, p, C_constraint, MR, MS):\n",
    "    \"\"\"\n",
    "    Run graph partitioning experiment using PRRP and compare against PyMETIS.\n",
    "    \n",
    "    Parameters:\n",
    "        graph_file_path (str): Path to the METIS-format graph file.\n",
    "        p (int): Desired number of partitions.\n",
    "        C_constraint (str): Cardinality constraint type (e.g., \"Uniform\" or \"Skewed\").\n",
    "        MR (int): Maximum iterations for growing a partition.\n",
    "        MS (int): Maximum allowed partition size before splitting.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with performance metrics and partition results for both PRRP and PyMETIS.\n",
    "    \"\"\"\n",
    "    # Load graph using METIS parser\n",
    "    logger.info(f\"Loading graph dataset from {graph_file_path} ...\")\n",
    "    try:\n",
    "        G_metis, num_nodes, num_edges = load_graph_from_metis(graph_file_path)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading graph: {e}\")\n",
    "        raise\n",
    "    \n",
    "    logger.info(f\"Graph loaded: {num_nodes} nodes, {num_edges} edges.\")\n",
    "    \n",
    "    # Run graph-based PRRP partitioning (from src/graph_prrp.py)\n",
    "    # Note: Here we assume that the PRRP function 'run_graph_prrp' is defined in that module.\n",
    "    from src.graph_prrp import run_graph_prrp\n",
    "    start_time = time.time()\n",
    "    prrp_partitions = run_graph_prrp(G_metis, p, None, MR, MS)\n",
    "    prrp_time = time.time() - start_time\n",
    "    logger.info(f\"Graph PRRP partitioning completed in {prrp_time:.2f} seconds.\")\n",
    "    \n",
    "    # Run PyMETIS partitioning for comparison\n",
    "    start_time = time.time()\n",
    "    pymetis_partitions = partition_graph_pymetis(G_metis, p)\n",
    "    pymetis_time = time.time() - start_time\n",
    "    logger.info(f\"PyMETIS partitioning completed in {pymetis_time:.2f} seconds.\")\n",
    "    \n",
    "    metrics = {\n",
    "        \"prrp_execution_time_sec\": prrp_time,\n",
    "        \"pymetis_execution_time_sec\": pymetis_time,\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_edges\": num_edges,\n",
    "        \"num_partitions\": p,\n",
    "        \"MR\": MR,\n",
    "        \"MS\": MS,\n",
    "        \"C_constraint\": C_constraint\n",
    "    }\n",
    "    return {\n",
    "        \"metrics\": metrics,\n",
    "        \"prrp_partitions\": prrp_partitions,\n",
    "        \"pymetis_partitions\": pymetis_partitions\n",
    "    }\n",
    "\n",
    "def save_results(results, filename):\n",
    "    \"\"\"\n",
    "    Save experiment results to a JSON file.\n",
    "    \n",
    "    Parameters:\n",
    "        results (dict): Results dictionary.\n",
    "        filename (str): Filename (including path) to save the JSON.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    logger.info(f\"Results saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiments and Collecting Metrics\n",
    "\n",
    "The following cells run the spatial and graph experiments over a range of parameter settings.\n",
    "For demonstration, we run a single configuration for each type. In practice, you might loop over\n",
    "multiple parameter combinations and aggregate the results into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a single spatial experiment configuration\n",
    "spatial_experiment_config = {\n",
    "    \"p_percentage\": 0.02,  # using 2% of dataset size for number of regions\n",
    "    \"M\": 10,\n",
    "    \"MR\": 30,\n",
    "    \"num_threads\": 2\n",
    "}\n",
    "spatial_results = run_spatial_experiment(spatial_dataset_path,\n",
    "                                           spatial_experiment_config[\"p_percentage\"],\n",
    "                                           spatial_experiment_config[\"M\"],\n",
    "                                           spatial_experiment_config[\"MR\"],\n",
    "                                           spatial_experiment_config[\"num_threads\"])\n",
    "# Save spatial results\n",
    "spatial_results_file = os.path.join(RESULTS_DIR, \"spatial_experiment_results.json\")\n",
    "save_results(spatial_results, spatial_results_file)\n",
    "\n",
<<<<<<< HEAD
    "# Path to the data folder\n",
    "data_folder = \"data\"\n",
    "shapefile_path = os.path.join(ROOT_DIR, \"data\", \"cb_2015_42_tract_500k\", \"cb_2015_42_tract_500k.shp\")\n",
    "print(f\"Path to shape file : {shapefile_path}\")\n",
    "\n",
    "graphfile_path = os.path.join(ROOT_DIR, \"data\", \"PGPgiantcompo.graph\")\n",
    "print(f\"Path to graph file : {graphfile_path}\")\n",
    "\n",
    "# List of datasets\n",
    "datasets = [shapefile_path, graphfile_path]\n",
    "\n",
    "# Dictionary to store success probabilities\n",
    "success_probabilities = {alg: [] for alg in algorithms}\n",
    "\n",
    "# Evaluate each algorithm on each dataset\n",
    "for dataset_path in datasets:\n",
    "    if dataset_path.endswith('.graph'):\n",
    "        area_data = load_graph_from_metis(dataset_path)\n",
    "    else:\n",
    "        area_data = load_shapefile(dataset_path)\n",
    "    for alg_name, alg_func in algorithms.items():\n",
    "        success_prob = evaluate_algorithm(alg_func, area_data)\n",
    "        success_probabilities[alg_name].append(success_prob)\n",
    "\n",
    "# Calculate average success probabilities\n",
    "average_success_probabilities = {alg: np.mean(probs) for alg, probs in success_probabilities.items()}\n",
    "\n",
    "print(\"Average Success Probabilities:\")\n",
    "for alg, avg_prob in average_success_probabilities.items():\n",
    "    print(f\"{alg}: {avg_prob:.2f}\")"
=======
    "# %% [code]\n",
    "# Run a single graph partitioning experiment configuration\n",
    "graph_experiment_config = {\n",
    "    \"p\": 10,\n",
    "    \"C_constraint\": \"Uniform\",\n",
    "    \"MR\": 20,\n",
    "    \"MS\": 10\n",
    "}\n",
    "graph_results = run_graph_experiment(graph_dataset_path,\n",
    "                                     graph_experiment_config[\"p\"],\n",
    "                                     graph_experiment_config[\"C_constraint\"],\n",
    "                                     graph_experiment_config[\"MR\"],\n",
    "                                     graph_experiment_config[\"MS\"])\n",
    "# Save graph results\n",
    "graph_results_file = os.path.join(RESULTS_DIR, \"graph_experiment_results.json\")\n",
    "save_results(graph_results, graph_results_file)"
>>>>>>> 7e74b9833b074fbe7284d13f38ecc6eae56327be
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Visualizations\n",
    "\n",
    "Here we generate a simple visualization of the execution time from the spatial experiment.\n",
    "In a full evaluation, you would plot multiple performance metrics across parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 08:53:34,161 - INFO - Preparing to generate 10 PRRP solutions using 10 parallel worker(s).\n",
      "2025-03-13 08:53:34,162 - INFO - Generated 10 random seeds for PRRP solutions.\n",
      "2025-03-13 08:53:34,162 - INFO - Starting parallel execution of PRRP solutions using multiprocessing.\n",
      "2025-03-13 08:53:35,055 - INFO - Worker started with seed 927079101.\n",
      "2025-03-13 08:53:35,055 - INFO - Worker started with seed 1139498393.\n",
      "2025-03-13 08:53:35,063 - INFO - Worker started with seed 990236826.\n",
      "2025-03-13 08:53:35,073 - INFO - Worker started with seed 134629034.\n",
      "2025-03-13 08:53:35,076 - INFO - Worker started with seed 596560566.\n",
      "2025-03-13 08:53:35,104 - INFO - Worker started with seed 1697512640.\n",
      "2025-03-13 08:53:35,114 - INFO - Worker started with seed 344184347.\n",
      "2025-03-13 08:53:35,143 - INFO - Worker started with seed 1128911327.\n",
      "2025-03-13 08:53:35,195 - INFO - Worker started with seed 1324919432.\n",
      "2025-03-13 08:53:35,252 - INFO - Worker started with seed 1796225902.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Coding/Projects/PRRP-Implementation/src/spatial_prrp.py\", line 517, in _prrp_worker\n    solution = run_prrp(areas, num_regions, cardinalities, solutions_count)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Volumes/Coding/Projects/PRRP-Implementation/src/spatial_prrp.py\", line 450, in run_prrp\n    if num_regions != len(cardinalities):\n                      ^^^^^^^^^^^^^^^^^^\nTypeError: object of type 'int' has no len()\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m         area_data = load_shapefile(dataset_path)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m alg_name, alg_func \u001b[38;5;129;01min\u001b[39;00m algorithms.items():\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         effectiveness = \u001b[43mevaluate_effectiveness\u001b[49m\u001b[43m(\u001b[49m\u001b[43malg_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m         effectiveness[alg_name].append(effectiveness)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Calculate average effectiveness\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mevaluate_effectiveness\u001b[39m\u001b[34m(algorithm, area_data, parameters)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cardinality \u001b[38;5;129;01min\u001b[39;00m parameters[\u001b[33m\"\u001b[39m\u001b[33mcardinalities\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m solutions_count \u001b[38;5;129;01min\u001b[39;00m parameters[\u001b[33m\"\u001b[39m\u001b[33msolutions_count\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         no_of_iterations, valid_solutions = \u001b[43malgorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43marea_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_regions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcardinality\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolutions_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m         effectiveness = \u001b[38;5;28mlen\u001b[39m(valid_solutions) / no_of_iterations \u001b[38;5;28;01mif\u001b[39;00m no_of_iterations > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEffectiveness for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_regions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m regions, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcardinality\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cardinality, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolutions_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m solutions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meffectiveness\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Coding/Projects/PRRP-Implementation/src/spatial_prrp.py:563\u001b[39m, in \u001b[36mrun_parallel_prrp\u001b[39m\u001b[34m(areas, num_regions, cardinalities, solutions_count, num_threads, use_multiprocessing)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=num_threads) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    560\u001b[39m         \u001b[38;5;66;03m# Each worker gets a unique seed, along with the areas, number of regions, and cardinalities.\u001b[39;00m\n\u001b[32m    561\u001b[39m         worker_args = [(seed, areas, num_regions, cardinalities, solutions_count)\n\u001b[32m    562\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds]\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m         solutions = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_prrp_worker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mParallel execution of PRRP solutions completed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py:375\u001b[39m, in \u001b[36mPool.starmap\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    370\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/prrp/lib/python3.11/multiprocessing/pool.py:774\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "def plot_execution_time(metric_list, title, xlabel, ylabel, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot execution time (or any metric) across experiments.\n",
    "    \n",
    "    Parameters:\n",
    "        metric_list (list or np.array): List of metric values.\n",
    "        title (str): Plot title.\n",
    "        xlabel (str): Label for x-axis.\n",
    "        ylabel (str): Label for y-axis.\n",
    "        save_path (str, optional): If provided, saves the figure to the given path.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(metric_list, marker='o', linestyle='-')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        logger.info(f\"Figure saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: plot spatial experiment execution time\n",
    "exec_time = spatial_results[\"metrics\"][\"execution_time_sec\"]\n",
    "# For demonstration we create a dummy list; in a full experiment you would loop over many parameter combinations.\n",
    "times = [exec_time, exec_time * 1.2, exec_time * 0.9]  # dummy data\n",
    "plot_execution_time(times, \"Spatial Experiment Execution Time\", \"Parameter Variation Index\", \"Time (sec)\",\n",
    "                    save_path=os.path.join(FIGURES_DIR, \"spatial_execution_time.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prrp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.11.11"
=======
   "version": "3.11.5"
>>>>>>> 7e74b9833b074fbe7284d13f38ecc6eae56327be
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
