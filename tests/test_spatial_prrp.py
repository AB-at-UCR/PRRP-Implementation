"""
tests/test_spatial_prrp.py

Unit tests for the revised Pâ€‘Regionalization through Recursive Partitioning (PRRP)
algorithm. This test suite covers:
  - Region Growing (expand_region_randomly)
  - Region Merging (integrate_components)
  - Region Splitting (adjust_region_size)
  - Full partitioning execution (run_prrp)
  - Parallel execution of partitioning (run_parallel_prrp)
  - Loading and processing of a real spatial dataset via shapefile
  - Construction and execution on synthetic grid data

Note:
For tests that use a real shapefile, it is assumed that the input areas are spatially
contiguous. Therefore, if the shapefile contains many areas, we filter them to the largest
connected component to ensure the algorithm can produce a valid solution.
"""

import os
import unittest
import random
from copy import deepcopy
from typing import Dict, Set, List, Any, Tuple

import networkx as nx

# Import functions from the revised spatial partitioning module.
from src.spatial_prrp import (
    expand_region_randomly,
    integrate_components,
    adjust_region_size,
    run_prrp,
    run_parallel_prrp
)
# Import the shapefile loader from the data loader module.
from src.prrp_data_loader import load_shapefile

# For generating synthetic geometries.
from shapely.geometry import box
import geopandas as gpd


# ==============================
# Helper Functions for Test Data
# ==============================

def generate_test_graph() -> Dict[int, Set[int]]:
    """
    Generates a small, manually designed adjacency list representing spatial areas.
    Returns a dictionary mapping each area id to a set of neighboring area ids.
    """
    return {
        1: {2, 5},
        2: {1, 3, 6},
        3: {2, 4, 7},
        4: {3, 8},
        5: {1, 6, 9},
        6: {2, 5, 7, 10},
        7: {3, 6, 8, 11},
        8: {4, 7, 12},
        9: {5, 10},
        10: {6, 9, 11},
        11: {7, 10, 12},
        12: {8, 11}
    }


def generate_test_areas() -> List[Dict[str, Any]]:
    """
    Generates a synthetic list of spatial areas with dummy geometry (None).
    Each area is represented as a dict with 'id' and 'geometry'.
    """
    return [{'id': i, 'geometry': None} for i in range(1, 13)]


def generate_grid_areas(rows: int, cols: int) -> List[Dict[str, Any]]:
    """
    Generates a grid of square polygons representing spatial areas.
    Each area is a square of unit length with sequential ids.
    """
    areas = []
    for i in range(rows):
        for j in range(cols):
            area_id = i * cols + j + 1
            polygon = box(j, i, j + 1, i + 1)
            areas.append({'id': area_id, 'geometry': polygon})
    return areas


def generate_grid_test_data(rows: int, cols: int) -> Tuple[List[Dict[str, Any]], Dict[int, Set[int]]]:
    """
    Generates synthetic grid test data and computes the expected rook-adjacency list.
    """
    areas = generate_grid_areas(rows, cols)
    expected_adj_list = {}
    for i in range(rows):
        for j in range(cols):
            area_id = i * cols + j + 1
            neighbors = set()
            if i > 0:
                neighbors.add((i - 1) * cols + j + 1)
            if i < rows - 1:
                neighbors.add((i + 1) * cols + j + 1)
            if j > 0:
                neighbors.add(i * cols + (j - 1) + 1)
            if j < cols - 1:
                neighbors.add(i * cols + (j + 1) + 1)
            expected_adj_list[area_id] = neighbors
    return areas, expected_adj_list


def build_graph_from_adj_list(adj_list: Dict[int, Set[int]]) -> nx.Graph:
    """
    Converts an adjacency list (dict of int to set of int) into a NetworkX Graph.
    """
    G = nx.Graph()
    for node, neighbors in adj_list.items():
        G.add_node(node)
        for neighbor in neighbors:
            G.add_edge(node, neighbor)
    return G


def build_graph_from_areas(areas: List[Dict[str, Any]]) -> nx.Graph:
    """
    Constructs a spatial graph from a list of area dictionaries.
    Two areas are considered adjacent if their geometries intersect.
    """
    G = nx.Graph()
    for area in areas:
        G.add_node(area['id'])
    # For testing, use a simple O(n^2) intersection check.
    for i in range(len(areas)):
        for j in range(i + 1, len(areas)):
            geom1 = areas[i]['geometry']
            geom2 = areas[j]['geometry']
            if geom1 is not None and geom2 is not None:
                if geom1.intersects(geom2):
                    G.add_edge(areas[i]['id'], areas[j]['id'])
    return G


def filter_to_largest_component(areas: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Given a list of area dicts (each with 'id' and 'geometry'),
    constructs a graph based on spatial intersections and returns only the areas
    belonging to the largest connected component.
    """
    G = build_graph_from_areas(areas)
    components = list(nx.connected_components(G))
    if not components:
        return areas
    largest_component_ids = max(components, key=len)
    filtered = [area for area in areas if area['id'] in largest_component_ids]
    return filtered


# ==============================
# Test Suite
# ==============================
class TestSpatialPRRP(unittest.TestCase):

    def setUp(self):
        """
        Initializes test data before each test case.
        Creates a synthetic spatial graph and a dummy list of areas.
        Also sets a fixed random seed for reproducibility.
        Note: For the tiny 12-node synthetic graph, we use a cardinality list that is feasible.
        Instead of [4, 4, 4], we use [5, 4, 3] (which sums to 12 and is in descending order).
        """
        random.seed(42)  # Fix the seed for reproducibility.
        self.adj_list: Dict[int, Set[int]] = generate_test_graph()
        self.available_areas: Set[int] = set(self.adj_list.keys())
        self.areas: List[Dict[str, Any]] = generate_test_areas()
        # Use a feasible cardinality list for the 12-node graph:
        self.cardinalities = [5, 4, 3]  # Sum is 12.
        self.num_regions = len(self.cardinalities)
        # Build a NetworkX graph from the synthetic adjacency list.
        self.graph = build_graph_from_adj_list(self.adj_list)

    # ==============================
    # 1. Test Region Growing (expand_region_randomly)
    # ==============================
    def test_grow_single_region(self):
        target_size = 4
        available = self.available_areas.copy()
        # Pick a random seed from the available areas.
        seed = random.choice(list(available))
        region = expand_region_randomly(
            self.graph, available, target_size, seed)
        self.assertEqual(len(region), target_size)
        # Verify connectivity using NetworkX.
        subgraph = self.graph.subgraph(region)
        components = list(nx.connected_components(subgraph))
        self.assertEqual(len(components), 1,
                         "The grown region is not contiguous.")

    def test_grow_single_region_insufficient_areas(self):
        available = {1, 2}
        target_size = 5
        seed = random.choice(list(available))
        with self.assertRaises(RuntimeError):
            # Expect failure due to insufficient available areas.
            expand_region_randomly(self.graph, available, target_size, seed)

    # ==============================
    # 2. Test Region Merging (integrate_components)
    # ==============================
    def test_merge_unassigned_components(self):
        region = {1, 2, 3, 4}
        available = self.available_areas.copy() - region
        # Manipulate available set to simulate disconnected components.
        available.discard(8)
        available.discard(11)
        available.add(12)
        merged_region = integrate_components(self.graph, available, region)
        self.assertIn(12, merged_region)

    # ==============================
    # 3. Test Region Splitting (adjust_region_size)
    # ==============================
    def test_adjust_region_size(self):
        # Create a region larger than the target and test trimming.
        region = {1, 2, 3, 4, 5, 6}
        target_size = 4
        adjusted_region = adjust_region_size(
            self.graph, region, target_size, self.available_areas)
        self.assertEqual(len(adjusted_region), target_size)
        # Check connectivity.
        subgraph = self.graph.subgraph(adjusted_region)
        components = list(nx.connected_components(subgraph))
        self.assertEqual(len(components), 1,
                         "Adjusted region is not contiguous.")

    # ==============================
    # 4. Test Full PRRP Execution (run_prrp) on Synthetic Data
    # ==============================
    def test_build_spatial_partitions(self):
        regions = run_prrp(self.graph, self.cardinalities)
        self.assertEqual(len(regions), self.num_regions)
        for i, region in enumerate(regions):
            self.assertEqual(len(region), self.cardinalities[i],
                             f"Region {i+1} does not match target size.")
        all_region_areas = set().union(*regions)
        expected_areas = set(range(1, 13))
        self.assertEqual(all_region_areas, expected_areas,
                         "Not all areas were assigned correctly.")

    # ==============================
    # 5. Test Parallel Execution of PRRP (run_parallel_prrp) on Synthetic Data
    # ==============================
    def test_run_parallel_partitioning(self):
        solutions_count = 3
        parallel_solutions = run_parallel_prrp(self.graph, self.cardinalities,
                                               num_solutions=solutions_count, num_threads=2)
        self.assertEqual(len(parallel_solutions), solutions_count)
        expected_areas = set(range(1, 13))
        for solution in parallel_solutions:
            self.assertEqual(len(solution), self.num_regions)
            union_areas = set().union(*solution)
            self.assertEqual(union_areas, expected_areas,
                             "A parallel solution did not cover all areas.")
        unique_solutions = {frozenset(frozenset(region)
                                      for region in sol) for sol in parallel_solutions}
        self.assertGreater(len(unique_solutions), 1,
                           "Parallel solutions are not unique.")

    # ==============================
    # 6. Test run_prrp with Invalid Cardinalities (should fail)
    # ==============================
    def test_build_spatial_partitions_invalid_cardinalities(self):
        # Cardinalities that do not sum up to the total number of areas.
        invalid_cardinalities = [5, 5, 5]  # Sum is 15 but total areas is 12.
        with self.assertRaises(RuntimeError):
            run_prrp(self.graph, invalid_cardinalities)

    # ==============================
    # 7. Test load_shapefile Integration
    # ==============================
    def test_load_shapefile(self):
        shapefile_path = os.path.abspath(os.path.join(
            os.getcwd(), 'data', 'cb_2015_42_tract_500k', 'cb_2015_42_tract_500k.shp'))
        if not os.path.exists(shapefile_path):
            self.skipTest(f"Shapefile not found at {shapefile_path}")
        areas = load_shapefile(shapefile_path)
        # Use a subset if the dataset is very large.
        areas = areas if len(areas) < 100 else random.sample(areas, 100)
        self.assertIsNotNone(areas)
        self.assertGreater(len(areas), 0)
        for area in areas:
            self.assertIn('id', area)
            self.assertIn('geometry', area)
            self.assertIsNotNone(area['geometry'])

    # ==============================
    # 8. Test run_prrp with a Real Dataset
    # ==============================
    def test_build_spatial_partitions_real_dataset(self):
        shapefile_path = os.path.abspath(os.path.join(
            os.getcwd(), 'data', 'cb_2015_42_tract_500k', 'cb_2015_42_tract_500k.shp'))
        if not os.path.exists(shapefile_path):
            self.skipTest(f"Shapefile not found at {shapefile_path}")
        areas = load_shapefile(shapefile_path)
        # Filter areas to the largest connected component.
        areas = filter_to_largest_component(areas)
        total_areas = len(areas)
        num_regions = max(1, int(0.01 * total_areas))

        # Instead of using random cardinalities that may be unbalanced,
        # compute an equal partition and adjust the last region.
        base = total_areas // num_regions
        cardinalities = [base] * num_regions
        cardinalities[-1] += total_areas - sum(cardinalities)
        # Ensure descending order (largest region first)
        cardinalities = sorted(cardinalities, reverse=True)

        # Build a spatial graph from the areas.
        graph = build_graph_from_areas(areas)
        regions = run_prrp(graph, cardinalities)
        self.assertEqual(len(regions), num_regions)
        all_assigned = set().union(*regions)
        expected_ids = {area['id'] for area in areas}
        self.assertEqual(all_assigned, expected_ids,
                         "Not all areas were assigned in the real dataset partitioning.")

    # ==============================
    # 9. Test Parallel Execution with a Real Dataset
    # ==============================

    def test_run_parallel_partitioning_real_dataset(self):
        shapefile_path = os.path.abspath(os.path.join(
            os.getcwd(), 'data', 'cb_2015_42_tract_500k', 'cb_2015_42_tract_500k.shp'))
        if not os.path.exists(shapefile_path):
            self.skipTest(f"Shapefile not found at {shapefile_path}")
        areas = load_shapefile(shapefile_path)
        areas = filter_to_largest_component(areas)
        total_areas = len(areas)
        num_regions = 5
        cardinalities = [random.randint(5, 15) for _ in range(num_regions - 1)]
        cardinalities.append(total_areas - sum(cardinalities))
        solutions_count = 3
        graph = build_graph_from_areas(areas)
        parallel_solutions = run_parallel_prrp(graph, cardinalities,
                                               num_solutions=solutions_count, num_threads=2)
        self.assertEqual(len(parallel_solutions), solutions_count)
        expected_ids = {area['id'] for area in areas}
        for solution in parallel_solutions:
            self.assertEqual(len(solution), num_regions)
            union_ids = set().union(*solution)
            self.assertEqual(
                union_ids, expected_ids, "A parallel real dataset solution did not cover all areas.")


if __name__ == '__main__':
    unittest.main()
